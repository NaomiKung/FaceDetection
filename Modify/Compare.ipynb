{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protective-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from process.resize import resize\n",
    "import cv2\n",
    "from process.crop_face import img_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "widespread-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for r, d, f in os.walk('image/'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            exact_path = r + file\n",
    "            files.append(exact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "directed-colombia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image/it_6.jpg',\n",
       " 'image/wave_7.jpg',\n",
       " 'image/it_5.jpg',\n",
       " 'image/oak_2.jpg',\n",
       " 'image/wave_8.jpg',\n",
       " 'image/beam_4.jpg',\n",
       " 'image/beam_3.jpg',\n",
       " 'image/oak_1.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "insured-powell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image/it_6.jpg can find face.\n",
      "image/it_5.jpg can find face.\n",
      "image/oak_2.jpg can find face.\n",
      "image/beam_4.jpg can find face.\n",
      "image/beam_3.jpg can find face.\n",
      "image/oak_1.jpg can find face.\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "face_done = []\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "for i in files:\n",
    "    image = cv2.imread(i)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    if type(faces) != tuple:\n",
    "        for x, y, w, h in faces:\n",
    "            img = image[x:x+w, y:y+h]\n",
    "            print(i + \" can find face.\")\n",
    "            face_done.append(i)\n",
    "\n",
    "            images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "likely-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "from Model.facenet_basemodel import FaceNet\n",
    "model = FaceNet().loadModel('./Model/facenet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "empirical-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "for img in images:\n",
    "    for i in face_done:\n",
    "        img_re = resize(img)\n",
    "        embedding = model.predict(img_re)[0, :]\n",
    "    \n",
    "        representation = []\n",
    "        representation.append(i)\n",
    "        representation.append(embedding)\n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "paperback-celebration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-aquarium",
   "metadata": {},
   "source": [
    "Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chronic-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "primary-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(representations), 1000000):\n",
    "    key = 'image/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-consensus",
   "metadata": {},
   "source": [
    "Spotify Annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entertaining-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "thousand-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size =128\n",
    "t = AnnoyIndex(embedding_size, 'angular')\n",
    "\n",
    "for i in range(0, len(representations)):\n",
    "    representation = representations[i]\n",
    "    img_path = representation[0]\n",
    "    embedding = representation[1]\n",
    "    \n",
    "    t.add_item(i, embedding)\n",
    "    \n",
    "t.build(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "olive-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.save('result.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "integral-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = AnnoyIndex(128, 'angular')\n",
    "n.load('result.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "horizontal-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198 191 249 249]]\n",
      "[30]\n",
      "['image/it_6.jpg', array([-0.7921088 ,  0.2920169 ,  0.32483315,  1.2468144 ,  0.8860202 ,\n",
      "        1.0491496 ,  1.1581718 , -0.6650983 , -0.60243326, -1.581208  ,\n",
      "        0.632371  , -1.408     , -0.93279684,  0.87667084, -1.414259  ,\n",
      "       -1.1295882 ,  1.3431023 , -2.032857  , -0.69040644, -0.4741681 ,\n",
      "       -0.19550328, -2.2388253 ,  1.5319884 ,  1.4266689 ,  0.6042202 ,\n",
      "        1.9383725 ,  2.0091598 ,  0.16813639, -0.42985165, -2.310195  ,\n",
      "        1.1581346 ,  0.9502694 ,  0.10712388, -0.1393038 , -0.6261446 ,\n",
      "        0.7705466 ,  1.1596378 , -0.7261128 ,  1.4950674 ,  0.36686623,\n",
      "       -0.45526722, -0.66222274, -0.43239918, -0.7374906 , -0.6629798 ,\n",
      "        1.8899657 ,  0.7332998 , -0.03091846, -1.0237244 , -0.99224126,\n",
      "        1.3079667 ,  1.1786598 ,  1.4535798 ,  0.36983395,  0.63690835,\n",
      "        4.5929832 , -0.04466813, -2.0361488 ,  2.2122607 ,  1.6630789 ,\n",
      "       -0.19632101,  0.17697594,  1.7501659 , -0.07061014, -0.510817  ,\n",
      "       -0.18340419,  0.6102153 ,  0.6493474 ,  0.6839676 ,  1.4819535 ,\n",
      "       -0.6117236 ,  1.361687  , -0.4719239 ,  0.91036457, -1.4007913 ,\n",
      "        1.7595758 , -0.74036264, -0.03042025, -1.1559794 , -1.8634987 ,\n",
      "        0.07520355,  0.88079095,  0.16522644,  0.59498453,  1.1012015 ,\n",
      "        0.08876133,  1.7009789 , -1.8408949 ,  0.49698022,  0.38131553,\n",
      "       -0.698605  , -1.3368952 ,  0.48774287, -0.29878387, -0.57229125,\n",
      "        1.6315076 ,  0.80826586, -0.9110706 ,  1.0082614 ,  1.0830566 ,\n",
      "       -1.3219563 , -0.6481632 ,  1.092123  , -0.00936682,  0.34674743,\n",
      "       -0.9081864 , -2.1479964 ,  2.0967734 , -0.03618269, -1.8413184 ,\n",
      "       -0.6810671 ,  0.56575483,  1.2563815 , -0.72117203,  0.08021419,\n",
      "        1.869752  , -0.77510226,  1.7360573 , -0.2012836 , -1.1198493 ,\n",
      "        1.1235118 , -1.7200894 ,  1.0294676 ,  0.877042  ,  0.01959459,\n",
      "        0.03106295,  1.4504298 , -1.1696037 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "path = './image/oak_1.jpg'\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector.detectMultiScale(gray, 1.1, 4)\n",
    "print(faces)\n",
    "for x, y, w, h in faces:\n",
    "    img_crop = img[x:x+w, y:y+h]\n",
    "\n",
    "img_re = cv2.resize(img_crop,(160,160))\n",
    "img_re = img_re[None,:,:,:]\n",
    "\n",
    "result = model.predict(img_re).reshape(-1, 1)\n",
    "idx = n.get_nns_by_vector(result, 1)\n",
    "\n",
    "print(idx)\n",
    "for i in idx:\n",
    "    print(representations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accurate-franklin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image/it_6.jpg',\n",
       " array([-0.7921088 ,  0.2920169 ,  0.32483315,  1.2468144 ,  0.8860202 ,\n",
       "         1.0491496 ,  1.1581718 , -0.6650983 , -0.60243326, -1.581208  ,\n",
       "         0.632371  , -1.408     , -0.93279684,  0.87667084, -1.414259  ,\n",
       "        -1.1295882 ,  1.3431023 , -2.032857  , -0.69040644, -0.4741681 ,\n",
       "        -0.19550328, -2.2388253 ,  1.5319884 ,  1.4266689 ,  0.6042202 ,\n",
       "         1.9383725 ,  2.0091598 ,  0.16813639, -0.42985165, -2.310195  ,\n",
       "         1.1581346 ,  0.9502694 ,  0.10712388, -0.1393038 , -0.6261446 ,\n",
       "         0.7705466 ,  1.1596378 , -0.7261128 ,  1.4950674 ,  0.36686623,\n",
       "        -0.45526722, -0.66222274, -0.43239918, -0.7374906 , -0.6629798 ,\n",
       "         1.8899657 ,  0.7332998 , -0.03091846, -1.0237244 , -0.99224126,\n",
       "         1.3079667 ,  1.1786598 ,  1.4535798 ,  0.36983395,  0.63690835,\n",
       "         4.5929832 , -0.04466813, -2.0361488 ,  2.2122607 ,  1.6630789 ,\n",
       "        -0.19632101,  0.17697594,  1.7501659 , -0.07061014, -0.510817  ,\n",
       "        -0.18340419,  0.6102153 ,  0.6493474 ,  0.6839676 ,  1.4819535 ,\n",
       "        -0.6117236 ,  1.361687  , -0.4719239 ,  0.91036457, -1.4007913 ,\n",
       "         1.7595758 , -0.74036264, -0.03042025, -1.1559794 , -1.8634987 ,\n",
       "         0.07520355,  0.88079095,  0.16522644,  0.59498453,  1.1012015 ,\n",
       "         0.08876133,  1.7009789 , -1.8408949 ,  0.49698022,  0.38131553,\n",
       "        -0.698605  , -1.3368952 ,  0.48774287, -0.29878387, -0.57229125,\n",
       "         1.6315076 ,  0.80826586, -0.9110706 ,  1.0082614 ,  1.0830566 ,\n",
       "        -1.3219563 , -0.6481632 ,  1.092123  , -0.00936682,  0.34674743,\n",
       "        -0.9081864 , -2.1479964 ,  2.0967734 , -0.03618269, -1.8413184 ,\n",
       "        -0.6810671 ,  0.56575483,  1.2563815 , -0.72117203,  0.08021419,\n",
       "         1.869752  , -0.77510226,  1.7360573 , -0.2012836 , -1.1198493 ,\n",
       "         1.1235118 , -1.7200894 ,  1.0294676 ,  0.877042  ,  0.01959459,\n",
       "         0.03106295,  1.4504298 , -1.1696037 ], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-accommodation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
